{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Simple Growing Container Example\n\nThis example shows how to instantiate a model with growing layers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Theo Rudkiewicz <theo.rudkiewicz@inria.fr>\n#          Sylvain Chevallier <sylvain.chevallier@universite-paris-saclay.fr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\nImporting the modules\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\n\nfrom gromo.containers.growing_container import GrowingContainer\nfrom gromo.modules.linear_growing_module import (\n    LinearGrowingModule,\n    LinearMergeGrowingModule,\n)\nfrom gromo.utils.utils import global_device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define your model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class GrowingNetwork(GrowingContainer):\n    def __init__(\n        self,\n        in_features: int = 5,\n        out_features: int = 1,\n        use_bias: bool = True,\n        hidden_features: int = 10,\n        device: torch.device = None,\n    ):\n        super(GrowingNetwork, self).__init__(\n            in_features=in_features,\n            out_features=out_features,\n            device=device,\n        )\n        self.start_module = LinearMergeGrowingModule(\n            in_features=self.in_features, name=\"start\"\n        )\n        self.l1 = LinearGrowingModule(\n            in_features=self.in_features,\n            out_features=hidden_features,\n            use_bias=use_bias,\n            post_layer_function=torch.nn.ReLU(),\n            name=\"l1\",\n        )\n        self.l2 = LinearGrowingModule(\n            in_features=hidden_features,\n            out_features=self.in_features,\n            name=\"l2\",\n            use_bias=use_bias,\n        )\n        self.res_module = LinearMergeGrowingModule(\n            in_features=self.in_features,\n            post_merge_function=torch.nn.ReLU(),\n            name=\"res\",\n        )\n        self.l3 = LinearGrowingModule(\n            in_features=self.in_features,\n            out_features=self.out_features,\n            name=\"l3\",\n            use_bias=use_bias,\n        )\n        self.l4 = LinearGrowingModule(\n            in_features=self.in_features,\n            out_features=hidden_features,\n            post_layer_function=torch.nn.ReLU(),\n            name=\"l4\",\n            use_bias=use_bias,\n        )\n        self.l5 = LinearGrowingModule(\n            in_features=hidden_features,\n            out_features=self.out_features,\n            name=\"l5\",\n            use_bias=use_bias,\n        )\n        self.end_module = LinearMergeGrowingModule(\n            in_features=self.out_features, name=\"end\"\n        )\n\n        self.start_module.set_next_modules([self.l1, self.res_module])\n        self.l1.previous_module = self.start_module\n        self.l1.next_module = self.l2\n        self.l2.previous_module = self.l1\n        self.l2.next_module = self.res_module\n        self.res_module.set_previous_modules([self.start_module, self.l2])\n        self.res_module.set_next_modules([self.l3, self.l4])\n        self.l3.previous_module = self.res_module\n        self.l3.next_module = self.end_module\n        self.l4.previous_module = self.res_module\n        self.l4.next_module = self.l5\n        self.l5.previous_module = self.l4\n        self.l5.next_module = self.end_module\n        self.end_module.set_previous_modules([self.l3, self.l5])\n\n        self.set_growing_layers()\n\n    def set_growing_layers(self):\n        self._growing_layers = [\n            self.start_module,\n            self.l1,\n            self.l2,\n            self.res_module,\n            self.l3,\n            self.l4,\n            self.l5,\n            self.end_module,\n        ]\n\n    def __str__(self, verbose=0):\n        if verbose == 0:\n            return super(GrowingNetwork, self).__str__()\n        else:\n            txt = [f\"{self.__class__.__name__}:\"]\n            for layer in self._growing_layers:\n                txt.append(layer.__str__(verbose=verbose))\n            return \"\\n\".join(txt)\n\n    def forward(self, x):\n        x = self.start_module(x)\n        x1 = self.l1(x)\n        x1 = self.l2(x1)\n        x = self.res_module(x + x1)\n        x1 = self.l3(x)\n        x = self.l4(x)\n        x = self.l5(x)\n        return self.end_module(x + x1)\n\n    def start_computing_s_m(self):\n        for layer in self._growing_layers:\n            layer.tensor_s.init()\n            if isinstance(layer, LinearGrowingModule):\n                layer.tensor_m.init()\n                layer.store_input = True\n                layer.store_pre_activity = True\n\n    def update_s_m(self):\n        for layer in self._growing_layers:\n            if isinstance(layer, LinearGrowingModule):\n                layer.tensor_m.update()\n                layer.tensor_s.update()\n\n    def pass_s_m(self, input_x, target_y, loss=torch.nn.MSELoss()):\n        input_x = input_x.to(self.device)\n        target_y = target_y.to(self.device)\n        self.zero_grad()\n        y = self(input_x)\n        loss_value = loss(y, target_y)\n        loss_value.backward()\n        self.update_s_m()\n\n    def stop_computing_s_m(self):\n        for layer in self._growing_layers:\n            layer.tensor_s.reset()\n            if isinstance(layer, LinearGrowingModule):\n                layer.tensor_m.reset()\n\n            if isinstance(layer, LinearMergeGrowingModule):\n                if layer.previous_tensor_s is not None:\n                    layer.previous_tensor_s.reset()\n                if layer.previous_tensor_m is not None:\n                    layer.previous_tensor_m.reset()\n            layer.store_input = False\n            layer.store_pre_activity = False\n\n\nif __name__ == \"__main__\":\n    device = global_device()\n    net = GrowingNetwork(5, 1, device=device)\n    x_input = torch.randn(20, 5, device=device)\n    y = net(x_input)\n    torch.norm(y).backward()\n\n    print(net)\n    print(net.l1.layer.weight.device)\n\n    # from torchinfo import summary\n    # summary(net, input_size=(1, 5), device=device)\n\n    print(net.l1.layer.weight.device)\n\n    for layer in net.children():\n        print(layer.__str__(verbose=2))\n\n    net.start_computing_s_m()\n\n    print(\"=\" * 80)\n    for layer in net.children():\n        print(layer.__str__(verbose=2))\n\n    net.end_module.previous_tensor_s.init()\n    net.end_module.previous_tensor_m.init()\n\n    for _ in range(2):\n        x_input = torch.randn(20, 5)\n        # net.zero_grad()\n        # y = net(x_input)\n        # torch.norm(y).backward()\n        net.pass_s_m(x_input, torch.zeros(20, 1))\n        net.end_module.previous_tensor_s.update()\n        net.end_module.previous_tensor_m.update()\n\n    for layer in net.children():\n        print(layer.__str__(verbose=2))\n\n    for layer in net.children():\n        if isinstance(layer, LinearGrowingModule):\n            layer.compute_optimal_delta()\n\n    for layer in net.children():\n        print(layer.__str__(verbose=2))\n\n    net.stop_computing_s_m()\n\n    for layer in net.children():\n        print(layer.__str__(verbose=2))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
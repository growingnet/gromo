
<!DOCTYPE html>


<html lang="en" data-content_root="../" data-theme="light">

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="gromo icon" sizes="300x168" href="../_static/gromo_small.png" type="image/png">
    <title>GroMo tutorial &#8212; GroMo 0.0.1-dev documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "light";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=7c1988a6" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../_static/jquery.js?v=5d32c60e"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
    <script src="../_static/documentation_options.js?v=5baf466d"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=XXXX"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'XXXX');
            </script>
    <script async="async" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'auto_examples/plot_tutorial';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="API Reference" href="../api.html" />
    <link rel="prev" title="MLP Example with Growing Layers" href="plot_mlp_run.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="0.0.1" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="light">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
    
    <img src="../_static/logo_bg_white_small.png" class="logo__image only-light" alt="GroMo 0.0.1-dev documentation - Home"/>
    <img src="../_static/logo_bg_white_small.png" class="logo__image only-dark pst-js-only" alt="GroMo 0.0.1-dev documentation - Home"/>
  
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item current active">
  <a class="nav-link nav-internal" href="index.html">
    Gallery
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api.html">
    API reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../whats_new.html">
    Release notes
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../tech_notes.html">
    Technical notes
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item current active">
  <a class="nav-link nav-internal" href="index.html">
    Gallery
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api.html">
    API reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../whats_new.html">
    Release notes
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../tech_notes.html">
    Technical notes
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="plot_growing_network.html">Simple Growing Container Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="plot_linear_module.html">Minimal Linear Growing Layers</a></li>
<li class="toctree-l1"><a class="reference internal" href="plot_mlp_run.html">MLP Example with Growing Layers</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">GroMo tutorial</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="index.html" class="nav-link">Examples</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">GroMo tutorial</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-examples-plot-tutorial-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="gromo-tutorial">
<span id="sphx-glr-auto-examples-plot-tutorial-py"></span><h1>GroMo tutorial<a class="headerlink" href="#gromo-tutorial" title="Link to this heading">#</a></h1>
<p>This is a minimal example of how to use GroMo. We will illustrate the
use off GroMo to find a one hidden layer neural network (NN) that
approximates the function <span class="math notranslate nohighlight">\(f(x) = \sin(x)\)</span> on the interval
<span class="math notranslate nohighlight">\([0, 2\pi]\)</span>.</p>
<section id="imports">
<h2>Imports<a class="headerlink" href="#imports" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>We use <code class="docutils literal notranslate"><span class="pre">torch</span></code> as the backend for all the computations.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">matplotlib</span></code> is used for plotting the results.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">global_device</span></code> is used to automatically select the device (CPU or
GPU) for computations.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">LinearGrowingModule</span></code> is the main class of GroMo, which implements
fully connected growing modules.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">SinDataLoader</span></code> is a custom data loader that generates the training
data for the sine function.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">train</span></code> is exactly like a <strong>standard PyTorch training loop</strong></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">evaluate</span></code> is exactly like a <strong>standard PyTorch evaluation loop</strong></p></li>
</ul>
<p>Then we define <code class="docutils literal notranslate"><span class="pre">plt_model</span></code> to visualize the model.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">helpers.auxilliary_functions</span><span class="w"> </span><span class="kn">import</span> <span class="n">SinDataloader</span><span class="p">,</span> <span class="n">evaluate_model</span><span class="p">,</span> <span class="n">train</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">gromo.modules.linear_growing_module</span><span class="w"> </span><span class="kn">import</span> <a href="../generated/gromo.modules.linear_growing_module.LinearGrowingModule.html#gromo.modules.linear_growing_module.LinearGrowingModule" title="gromo.modules.linear_growing_module.LinearGrowingModule" class="sphx-glr-backref-module-gromo-modules-linear_growing_module sphx-glr-backref-type-py-class"><span class="n">LinearGrowingModule</span></a>
<span class="kn">from</span><span class="w"> </span><span class="nn">gromo.utils.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">global_device</span>


<span class="n">global_device</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>device(type=&#39;cpu&#39;)
</pre></div>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">plt_model</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.figure.Figure.html#matplotlib.figure.Figure" title="matplotlib.figure.Figure" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fig</span></a><span class="p">:</span> <span class="s2">&quot;plt.axes._axes.Axes&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Plot the model&#39;s predictions and the true function.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    model : torch.nn.Module</span>
<span class="sd">        The model to plot.</span>
<span class="sd">    fig : plt.axes._axes.Axes</span>
<span class="sd">        The figure to plot on.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    None</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch</span><span class="o">.</span><span class="n">pi</span></a><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">global_device</span><span class="p">())</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.figure.Figure.html#matplotlib.figure.Figure" title="matplotlib.figure.Figure" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fig</span><span class="o">.</span><span class="n">plot</span></a><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">y</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;sin&quot;</span><span class="p">)</span>
    <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.figure.Figure.html#matplotlib.figure.Figure" title="matplotlib.figure.Figure" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fig</span><span class="o">.</span><span class="n">plot</span></a><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Predicted&quot;</span><span class="p">)</span>
    <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.figure.Figure.legend.html#matplotlib.figure.Figure.legend" title="matplotlib.figure.Figure.legend" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-method"><span class="n">fig</span><span class="o">.</span><span class="n">legend</span></a><span class="p">()</span>
    <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.figure.Figure.html#matplotlib.figure.Figure" title="matplotlib.figure.Figure" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fig</span><span class="o">.</span><span class="n">set_xlabel</span></a><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
    <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.figure.Figure.html#matplotlib.figure.Figure" title="matplotlib.figure.Figure" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fig</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_label_position</span></a><span class="p">(</span><span class="s2">&quot;right&quot;</span><span class="p">)</span>
    <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.figure.Figure.html#matplotlib.figure.Figure" title="matplotlib.figure.Figure" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fig</span><span class="o">.</span><span class="n">set_ylabel</span></a><span class="p">(</span><span class="s2">&quot;sin(x)&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">SinDataloader</span><span class="p">(</span><span class="n">nb_sample</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="define-the-model">
<h2>1. Define the model<a class="headerlink" href="#define-the-model" title="Link to this heading">#</a></h2>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="../generated/gromo.modules.linear_growing_module.LinearGrowingModule.html#gromo.modules.linear_growing_module.LinearGrowingModule" title="gromo.modules.linear_growing_module.LinearGrowingModule" class="sphx-glr-backref-module-gromo-modules-linear_growing_module sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">first_layer</span></a> <span class="o">=</span> <a href="../generated/gromo.modules.linear_growing_module.LinearGrowingModule.html#gromo.modules.linear_growing_module.LinearGrowingModule" title="gromo.modules.linear_growing_module.LinearGrowingModule" class="sphx-glr-backref-module-gromo-modules-linear_growing_module sphx-glr-backref-type-py-class"><span class="n">LinearGrowingModule</span></a><span class="p">(</span>
    <span class="n">in_features</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">out_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">use_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">post_layer_function</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">(),</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;first_layer&quot;</span><span class="p">,</span>
<span class="p">)</span>

<a href="../generated/gromo.modules.linear_growing_module.LinearGrowingModule.html#gromo.modules.linear_growing_module.LinearGrowingModule" title="gromo.modules.linear_growing_module.LinearGrowingModule" class="sphx-glr-backref-module-gromo-modules-linear_growing_module sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">second_layer</span></a> <span class="o">=</span> <a href="../generated/gromo.modules.linear_growing_module.LinearGrowingModule.html#gromo.modules.linear_growing_module.LinearGrowingModule" title="gromo.modules.linear_growing_module.LinearGrowingModule" class="sphx-glr-backref-module-gromo-modules-linear_growing_module sphx-glr-backref-type-py-class"><span class="n">LinearGrowingModule</span></a><span class="p">(</span>
    <span class="n">in_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">out_features</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;second_layer&quot;</span><span class="p">,</span>
    <span class="n">previous_module</span><span class="o">=</span><a href="../generated/gromo.modules.linear_growing_module.LinearGrowingModule.html#gromo.modules.linear_growing_module.LinearGrowingModule" title="gromo.modules.linear_growing_module.LinearGrowingModule" class="sphx-glr-backref-module-gromo-modules-linear_growing_module sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">first_layer</span></a><span class="p">,</span>
<span class="p">)</span>

<span class="n">growing_net</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <a href="../generated/gromo.modules.linear_growing_module.LinearGrowingModule.html#gromo.modules.linear_growing_module.LinearGrowingModule" title="gromo.modules.linear_growing_module.LinearGrowingModule" class="sphx-glr-backref-module-gromo-modules-linear_growing_module sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">first_layer</span></a><span class="p">,</span>
    <a href="../generated/gromo.modules.linear_growing_module.LinearGrowingModule.html#gromo.modules.linear_growing_module.LinearGrowingModule" title="gromo.modules.linear_growing_module.LinearGrowingModule" class="sphx-glr-backref-module-gromo-modules-linear_growing_module sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">second_layer</span></a><span class="p">,</span>
<span class="p">)</span>

<span class="n">growing_net</span> <span class="o">=</span> <span class="n">growing_net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">global_device</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="n">growing_net</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Sequential(
  (0): LinearGrowingModule(LinearGrowingModule(first_layer))(in_features=1, out_features=2, use_bias=True)
  (1): LinearGrowingModule(LinearGrowingModule(second_layer))(in_features=2, out_features=1, use_bias=True)
)
</pre></div>
</div>
<p>Here we define the following network:</p>
<div class="math notranslate nohighlight">
\[\begin{split}x \mapsto \begin{bmatrix} z_1 \\ z_2 \end{bmatrix} \mapsto \begin{bmatrix} \sigma(z_1) \\ \sigma(z_2) \end{bmatrix} \mapsto y\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\sigma\)</span> is the activation function, <span class="math notranslate nohighlight">\(z_1\)</span> and
<span class="math notranslate nohighlight">\(z_2\)</span> are the outputs of the first fully connected layer, and
<span class="math notranslate nohighlight">\(y\)</span> is the output of the whole network.</p>
<p>Note that the <strong>activation function is included in the first
``LinearGrowingModule`` layer</strong>, this allow to easily access the
intermediate results both before and after the activation function.</p>
<p>Note also that the second layer is linked to the first one by
<code class="docutils literal notranslate"><span class="pre">previous_module=first_layer</span></code>. This allows extending the input of the
second layer and let it grow with the first layer.</p>
<section id="use-it-like-a-normal-model">
<h3>2. Use it like a normal model<a class="headerlink" href="#use-it-like-a-normal-model" title="Link to this heading">#</a></h3>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">l2_err</span></a> <span class="o">=</span> <span class="n">evaluate_model</span><span class="p">(</span><span class="n">growing_net</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">loss_function</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Initial error: </span><span class="si">{</span><a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">l2_err</span></a><span class="si">:</span><span class="s2">.2e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.figure.Figure.html#matplotlib.figure.Figure" title="matplotlib.figure.Figure" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fig</span></a><span class="p">,</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="matplotlib.axes.Axes" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span></a> <span class="o">=</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt_model</span><span class="p">(</span><span class="n">growing_net</span><span class="p">,</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="matplotlib.axes.Axes" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span></a><span class="p">)</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_plot_tutorial_001.png" srcset="../_images/sphx_glr_plot_tutorial_001.png" alt="plot tutorial" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Initial error: 6.69e+00
</pre></div>
</div>
<p>Here we guide it a bit in the right direction to make it learn faster</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">growing_net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">growing_net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
<span class="n">growing_net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span> <span class="o">*</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch</span><span class="o">.</span><span class="n">pi</span></a> <span class="o">/</span> <span class="mi">2</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">global_device</span><span class="p">())</span>
<span class="n">growing_net</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">]],</span> <span class="n">device</span><span class="o">=</span><span class="n">global_device</span><span class="p">())</span>
<span class="n">growing_net</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">growing_net</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">l2_err</span></a> <span class="o">=</span> <span class="n">evaluate_model</span><span class="p">(</span><span class="n">growing_net</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">loss_function</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error: </span><span class="si">{</span><a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">l2_err</span></a><span class="si">:</span><span class="s2">.2e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.figure.Figure.html#matplotlib.figure.Figure" title="matplotlib.figure.Figure" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fig</span></a><span class="p">,</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="matplotlib.axes.Axes" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span></a> <span class="o">=</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt_model</span><span class="p">(</span><span class="n">growing_net</span><span class="p">,</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="matplotlib.axes.Axes" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span></a><span class="p">)</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_plot_tutorial_002.png" srcset="../_images/sphx_glr_plot_tutorial_002.png" alt="plot tutorial" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Error: 1.48e+00
</pre></div>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">growing_net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">)</span>
<span class="c1"># optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)</span>

<a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">res</span></a> <span class="o">=</span> <span class="n">train</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">growing_net</span><span class="p">,</span>
    <span class="n">train_dataloader</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
    <span class="n">nb_epoch</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">show</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">aux_loss_function</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">loss_train</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">accuracy_train</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">loss_val</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">_</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">res</span></a>
<a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html#matplotlib.pyplot.plot" title="matplotlib.pyplot.plot" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">loss_train</span></a><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
<a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html#matplotlib.pyplot.plot" title="matplotlib.pyplot.plot" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">loss_val</span></a><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;val&quot;</span><span class="p">)</span>
<a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.legend.html#matplotlib.pyplot.legend" title="matplotlib.pyplot.legend" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">legend</span></a><span class="p">()</span>
<a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.show.html#matplotlib.pyplot.show" title="matplotlib.pyplot.show" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">show</span></a><span class="p">()</span>

<a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">l2_err</span></a> <span class="o">=</span> <span class="n">evaluate_model</span><span class="p">(</span><span class="n">growing_net</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">loss_function</span><span class="p">,</span> <span class="n">aux_loss_function</span><span class="o">=</span><span class="kc">None</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error: </span><span class="si">{</span><a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">l2_err</span></a><span class="si">:</span><span class="s2">.2e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.figure.Figure.html#matplotlib.figure.Figure" title="matplotlib.figure.Figure" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fig</span></a><span class="p">,</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="matplotlib.axes.Axes" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span></a> <span class="o">=</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt_model</span><span class="p">(</span><span class="n">growing_net</span><span class="p">,</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="matplotlib.axes.Axes" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span></a><span class="p">)</span>
</pre></div>
</div>
<ul class="sphx-glr-horizontal">
<li><img src="../_images/sphx_glr_plot_tutorial_003.png" srcset="../_images/sphx_glr_plot_tutorial_003.png" alt="plot tutorial" class = "sphx-glr-multi-img"/></li>
<li><img src="../_images/sphx_glr_plot_tutorial_004.png" srcset="../_images/sphx_glr_plot_tutorial_004.png" alt="plot tutorial" class = "sphx-glr-multi-img"/></li>
</ul>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Error: 5.13e-02
</pre></div>
</div>
<p>Here with only two hidden neurons, we have a limited expressiveness.
Therefore we would like to add new neurons to the model.</p>
</section>
</section>
<section id="prepare-the-growth">
<h2>3. Prepare the growth<a class="headerlink" href="#prepare-the-growth" title="Link to this heading">#</a></h2>
<p>To add new neurons we need information about the current model. To get
those the first set is to initialize the computation of those.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">growing_net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="fm">__str__</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">growing_net</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="fm">__str__</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>LinearGrowingModule(first_layer) module with 4 parameters.
        Layer : Linear(in_features=1, out_features=2, bias=True)
        Post layer function : GELU(approximate=&#39;none&#39;)
        Allow growing : False
        Store input : False
        self._internal_store_input=False
        Store pre-activity : False
        self._internal_store_pre_activity=False
        Tensor S (internal) : S(LinearGrowingModule(first_layer)) tensor of shape (2, 2) with 0 samples
        Tensor S : S(LinearGrowingModule(first_layer)) tensor of shape (2, 2) with 0 samples
        Tensor M : M(LinearGrowingModule(first_layer)) tensor of shape (2, 2) with 0 samples
        Optimal delta layer : None
        Extended input layer : None
        Extended output layer : None
LinearGrowingModule(second_layer) module with 3 parameters.
        Layer : Linear(in_features=2, out_features=1, bias=True)
        Post layer function : Identity()
        Allow growing : False
        Store input : False
        self._internal_store_input=False
        Store pre-activity : False
        self._internal_store_pre_activity=False
        Tensor S (internal) : S(LinearGrowingModule(second_layer)) tensor of shape (3, 3) with 0 samples
        Tensor S : S(LinearGrowingModule(second_layer)) tensor of shape (3, 3) with 0 samples
        Tensor M : M(LinearGrowingModule(second_layer)) tensor of shape (3, 1) with 0 samples
        Optimal delta layer : None
        Extended input layer : None
        Extended output layer : None
</pre></div>
</div>
<p>Above you can see that nothing is stored in the model.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">growing_net</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">init_computation</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">growing_net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="fm">__str__</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">growing_net</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="fm">__str__</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>LinearGrowingModule(first_layer) module with 4 parameters.
        Layer : Linear(in_features=1, out_features=2, bias=True)
        Post layer function : GELU(approximate=&#39;none&#39;)
        Allow growing : False
        Store input : True
        self._internal_store_input=True
        Store pre-activity : False
        self._internal_store_pre_activity=False
        Tensor S (internal) : S(LinearGrowingModule(first_layer)) tensor of shape (2, 2) with 0 samples
        Tensor S : S(LinearGrowingModule(first_layer)) tensor of shape (2, 2) with 0 samples
        Tensor M : M(LinearGrowingModule(first_layer)) tensor of shape (2, 2) with 0 samples
        Optimal delta layer : None
        Extended input layer : None
        Extended output layer : None
LinearGrowingModule(second_layer) module with 3 parameters.
        Layer : Linear(in_features=2, out_features=1, bias=True)
        Post layer function : Identity()
        Allow growing : False
        Store input : True
        self._internal_store_input=True
        Store pre-activity : True
        self._internal_store_pre_activity=True
        Tensor S (internal) : S(LinearGrowingModule(second_layer)) tensor of shape (3, 3) with 0 samples
        Tensor S : S(LinearGrowingModule(second_layer)) tensor of shape (3, 3) with 0 samples
        Tensor M : M(LinearGrowingModule(second_layer)) tensor of shape (3, 1) with 0 samples
        Optimal delta layer : None
        Extended input layer : None
        Extended output layer : None
</pre></div>
</div>
<p>Above you can see that one the computation are initialised, we see that
<code class="docutils literal notranslate"><span class="pre">Store</span> <span class="pre">input</span> <span class="pre">:</span> <span class="pre">True</span></code>. This means that the next time we forward through
the graph we will store the input of the layers for which
<code class="docutils literal notranslate"><span class="pre">store_input=True</span></code>.</p>
<p>We then do the forward/backward pass to compute all the raw information
needed, then we call <code class="docutils literal notranslate"><span class="pre">update_computation</span></code> to aggregate the raw
informatons into statistics like the tensors S and M.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Here we switch to a sum loss function !</span>
<span class="c1"># This is important as we already make the average internally</span>
<span class="n">loss_sum</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;sum&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">sinx</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">growing_net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="n">error</span> <span class="o">=</span> <span class="n">loss_sum</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">sinx</span><span class="p">)</span>
    <span class="n">error</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="n">growing_net</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">update_computation</span><span class="p">()</span>
</pre></div>
</div>
<p>Below you can see that indeed <code class="docutils literal notranslate"><span class="pre">Tensor</span> <span class="pre">S</span></code> and <code class="docutils literal notranslate"><span class="pre">Tensor</span> <span class="pre">M</span></code> are now
estimated over 1000 samples.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">growing_net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="fm">__str__</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">growing_net</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="fm">__str__</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>LinearGrowingModule(first_layer) module with 4 parameters.
        Layer : Linear(in_features=1, out_features=2, bias=True)
        Post layer function : GELU(approximate=&#39;none&#39;)
        Allow growing : False
        Store input : True
        self._internal_store_input=True
        Store pre-activity : False
        self._internal_store_pre_activity=False
        Tensor S (internal) : S(LinearGrowingModule(first_layer)) tensor of shape (2, 2) with 1000 samples
        Tensor S : S(LinearGrowingModule(first_layer)) tensor of shape (2, 2) with 1000 samples
        Tensor M : M(LinearGrowingModule(first_layer)) tensor of shape (2, 2) with 0 samples
        Optimal delta layer : None
        Extended input layer : None
        Extended output layer : None
LinearGrowingModule(second_layer) module with 3 parameters.
        Layer : Linear(in_features=2, out_features=1, bias=True)
        Post layer function : Identity()
        Allow growing : False
        Store input : True
        self._internal_store_input=True
        Store pre-activity : True
        self._internal_store_pre_activity=True
        Tensor S (internal) : S(LinearGrowingModule(second_layer)) tensor of shape (3, 3) with 1000 samples
        Tensor S : S(LinearGrowingModule(second_layer)) tensor of shape (3, 3) with 1000 samples
        Tensor M : M(LinearGrowingModule(second_layer)) tensor of shape (3, 1) with 1000 samples
        Optimal delta layer : None
        Extended input layer : None
        Extended output layer : None
</pre></div>
</div>
<p>Then we can compute the natural gradient step and the new neurons to add
with <code class="docutils literal notranslate"><span class="pre">compute_optimal_updates</span></code>. You can see that now the first layer
store an extended output layer that will compute the new values of the
neurons. The second layer has also been extended with an extended input
layer. In addition the second layer has a <code class="docutils literal notranslate"><span class="pre">Optimal</span> <span class="pre">delta</span> <span class="pre">layer</span></code> which
correspond to the natural gradient step.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">growing_net</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">compute_optimal_updates</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">growing_net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="fm">__str__</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">growing_net</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="fm">__str__</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>LinearGrowingModule(first_layer) module with 4 parameters.
        Layer : Linear(in_features=1, out_features=2, bias=True)
        Post layer function : GELU(approximate=&#39;none&#39;)
        Allow growing : False
        Store input : True
        self._internal_store_input=True
        Store pre-activity : False
        self._internal_store_pre_activity=False
        Tensor S (internal) : S(LinearGrowingModule(first_layer)) tensor of shape (2, 2) with 1000 samples
        Tensor S : S(LinearGrowingModule(first_layer)) tensor of shape (2, 2) with 1000 samples
        Tensor M : M(LinearGrowingModule(first_layer)) tensor of shape (2, 2) with 0 samples
        Optimal delta layer : None
        Extended input layer : None
        Extended output layer : Linear(in_features=1, out_features=1, bias=True)
LinearGrowingModule(second_layer) module with 3 parameters.
        Layer : Linear(in_features=2, out_features=1, bias=True)
        Post layer function : Identity()
        Allow growing : False
        Store input : True
        self._internal_store_input=True
        Store pre-activity : True
        self._internal_store_pre_activity=True
        Tensor S (internal) : S(LinearGrowingModule(second_layer)) tensor of shape (3, 3) with 1000 samples
        Tensor S : S(LinearGrowingModule(second_layer)) tensor of shape (3, 3) with 1000 samples
        Tensor M : M(LinearGrowingModule(second_layer)) tensor of shape (3, 1) with 1000 samples
        Optimal delta layer : Linear(in_features=2, out_features=1, bias=True)
        Extended input layer : Linear(in_features=1, out_features=1, bias=True)
        Extended output layer : None
</pre></div>
</div>
<p>Once the updates are computed we can stop computing statistics and
storing them. This is done by calling the <code class="docutils literal notranslate"><span class="pre">reset_computation</span></code> method.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">growing_net</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reset_computation</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">growing_net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="fm">__str__</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">growing_net</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="fm">__str__</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>LinearGrowingModule(first_layer) module with 4 parameters.
        Layer : Linear(in_features=1, out_features=2, bias=True)
        Post layer function : GELU(approximate=&#39;none&#39;)
        Allow growing : False
        Store input : True
        self._internal_store_input=True
        Store pre-activity : False
        self._internal_store_pre_activity=False
        Tensor S (internal) : S(LinearGrowingModule(first_layer)) tensor of shape (2, 2) with 0 samples
        Tensor S : S(LinearGrowingModule(first_layer)) tensor of shape (2, 2) with 0 samples
        Tensor M : M(LinearGrowingModule(first_layer)) tensor of shape (2, 2) with 0 samples
        Optimal delta layer : None
        Extended input layer : None
        Extended output layer : Linear(in_features=1, out_features=1, bias=True)
LinearGrowingModule(second_layer) module with 3 parameters.
        Layer : Linear(in_features=2, out_features=1, bias=True)
        Post layer function : Identity()
        Allow growing : False
        Store input : False
        self._internal_store_input=False
        Store pre-activity : False
        self._internal_store_pre_activity=False
        Tensor S (internal) : S(LinearGrowingModule(second_layer)) tensor of shape (3, 3) with 0 samples
        Tensor S : S(LinearGrowingModule(second_layer)) tensor of shape (3, 3) with 0 samples
        Tensor M : M(LinearGrowingModule(second_layer)) tensor of shape (3, 1) with 0 samples
        Optimal delta layer : Linear(in_features=2, out_features=1, bias=True)
        Extended input layer : Linear(in_features=1, out_features=1, bias=True)
        Extended output layer : None
</pre></div>
</div>
<p>Here we can see that the first layer still store the input. To correct
it we can simply set <code class="docutils literal notranslate"><span class="pre">store_input=False</span></code> in the first layer.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">growing_net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">store_input</span> <span class="o">=</span> <span class="kc">False</span>
<span class="nb">print</span><span class="p">(</span><span class="n">growing_net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="fm">__str__</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">growing_net</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="fm">__str__</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>LinearGrowingModule(first_layer) module with 4 parameters.
        Layer : Linear(in_features=1, out_features=2, bias=True)
        Post layer function : GELU(approximate=&#39;none&#39;)
        Allow growing : False
        Store input : False
        self._internal_store_input=False
        Store pre-activity : False
        self._internal_store_pre_activity=False
        Tensor S (internal) : S(LinearGrowingModule(first_layer)) tensor of shape (2, 2) with 0 samples
        Tensor S : S(LinearGrowingModule(first_layer)) tensor of shape (2, 2) with 0 samples
        Tensor M : M(LinearGrowingModule(first_layer)) tensor of shape (2, 2) with 0 samples
        Optimal delta layer : None
        Extended input layer : None
        Extended output layer : Linear(in_features=1, out_features=1, bias=True)
LinearGrowingModule(second_layer) module with 3 parameters.
        Layer : Linear(in_features=2, out_features=1, bias=True)
        Post layer function : Identity()
        Allow growing : False
        Store input : False
        self._internal_store_input=False
        Store pre-activity : False
        self._internal_store_pre_activity=False
        Tensor S (internal) : S(LinearGrowingModule(second_layer)) tensor of shape (3, 3) with 0 samples
        Tensor S : S(LinearGrowingModule(second_layer)) tensor of shape (3, 3) with 0 samples
        Tensor M : M(LinearGrowingModule(second_layer)) tensor of shape (3, 1) with 0 samples
        Optimal delta layer : Linear(in_features=2, out_features=1, bias=True)
        Extended input layer : Linear(in_features=1, out_features=1, bias=True)
        Extended output layer : None
</pre></div>
</div>
</section>
<section id="choose-a-scaling-factor">
<h2>4. Choose a scaling factor<a class="headerlink" href="#choose-a-scaling-factor" title="Link to this heading">#</a></h2>
<p>Once we computed the updates we can choose a scaling factor. This
scaling factor <span class="math notranslate nohighlight">\(\gamma\)</span> will scale the updates by <span class="math notranslate nohighlight">\(\gamma\)</span>
when they have a quadratic effect (like the new incoming and outgoing
weights) or <span class="math notranslate nohighlight">\(\gamma^2\)</span> when they have a linear effect (like the
natural gradient step).</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">growing_net</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">scaling_factor</span> <span class="o">=</span> <span class="mf">0.5</span>
</pre></div>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">extended_evaluate_model</span><span class="p">(</span>
    <span class="n">growing_model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">,</span>
    <span class="n">dataloader</span><span class="p">:</span> <a href="https://docs.python.org/3/library/typing.html#typing.Generic" title="typing.Generic" class="sphx-glr-backref-module-typing sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span></a><span class="p">,</span>
    <span class="n">loss_function</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;sum&quot;</span><span class="p">),</span>
    <span class="n">batch_limit</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">global_device</span><span class="p">(),</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="k">assert</span> <span class="p">(</span>
        <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">loss_function</span><span class="o">.</span><span class="n">reduction</span></a> <span class="o">==</span> <span class="s2">&quot;sum&quot;</span>
    <span class="p">),</span> <span class="s2">&quot;The loss function should not be averaged over the batch&quot;</span>
    <span class="n">growing_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">n_batch</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">nb_sample</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
        <span class="n">growing_model</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">z_ext</span> <span class="o">=</span> <span class="n">growing_model</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">extended_forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y_pred</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">_</span></a> <span class="o">=</span> <span class="n">growing_model</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">extended_forward</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">z_ext</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span>
        <span class="n">nb_sample</span> <span class="o">+=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">n_batch</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">batch_limit</span> <span class="o">&lt;=</span> <span class="n">n_batch</span><span class="p">:</span>
            <span class="k">break</span>
    <span class="k">return</span> <span class="n">total_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="n">nb_sample</span>
</pre></div>
</div>
<p>We can use a special forward <code class="docutils literal notranslate"><span class="pre">extended_forward</span></code> that takes into
account the proposed modification of the network to evaluate their
effect on the loss.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">new_error</span></a> <span class="o">=</span> <span class="n">extended_evaluate_model</span><span class="p">(</span>
    <span class="n">growing_net</span><span class="p">,</span>
    <span class="n">data</span><span class="p">,</span>
    <span class="n">loss_sum</span><span class="p">,</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;New error: </span><span class="si">{</span><a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">new_error</span></a><span class="si">:</span><span class="s2">.2e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>New error: 3.99e-02
</pre></div>
</div>
<section id="apply-the-changes">
<h3>5. Apply the changes<a class="headerlink" href="#apply-the-changes" title="Link to this heading">#</a></h3>
<p>Once we have chosen a scaling factor we can apply the changes to the
model. This is done by calling the <code class="docutils literal notranslate"><span class="pre">apply_change</span></code> methods.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">growing_net</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">apply_change</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">growing_net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="fm">__str__</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">growing_net</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="fm">__str__</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>LinearGrowingModule(first_layer) module with 6 parameters.
        Layer : Linear(in_features=1, out_features=3, bias=True)
        Post layer function : GELU(approximate=&#39;none&#39;)
        Allow growing : False
        Store input : False
        self._internal_store_input=False
        Store pre-activity : False
        self._internal_store_pre_activity=False
        Tensor S (internal) : S(LinearGrowingModule(first_layer)) tensor of shape (2, 2) with 0 samples
        Tensor S : S(LinearGrowingModule(first_layer)) tensor of shape (2, 2) with 0 samples
        Tensor M : M(LinearGrowingModule(first_layer)) tensor of shape (2, 3) with 0 samples
        Optimal delta layer : None
        Extended input layer : None
        Extended output layer : Linear(in_features=1, out_features=1, bias=True)
LinearGrowingModule(second_layer) module with 4 parameters.
        Layer : Linear(in_features=3, out_features=1, bias=True)
        Post layer function : Identity()
        Allow growing : False
        Store input : False
        self._internal_store_input=False
        Store pre-activity : False
        self._internal_store_pre_activity=False
        Tensor S (internal) : S(LinearGrowingModule(second_layer)) tensor of shape (4, 4) with 0 samples
        Tensor S : S(LinearGrowingModule(second_layer)) tensor of shape (4, 4) with 0 samples
        Tensor M : M(LinearGrowingModule(second_layer)) tensor of shape (4, 1) with 0 samples
        Optimal delta layer : Linear(in_features=2, out_features=1, bias=True)
        Extended input layer : Linear(in_features=1, out_features=1, bias=True)
        Extended output layer : None
</pre></div>
</div>
<p>We can then delete the <code class="docutils literal notranslate"><span class="pre">extended_output_layer</span></code>,
<code class="docutils literal notranslate"><span class="pre">extended_input_layer</span></code> and <code class="docutils literal notranslate"><span class="pre">Optimal</span> <span class="pre">delta</span> <span class="pre">layer</span></code> as they are not
needed anymore.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">growing_net</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">delete_update</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">growing_net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="fm">__str__</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">growing_net</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="fm">__str__</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>LinearGrowingModule(first_layer) module with 6 parameters.
        Layer : Linear(in_features=1, out_features=3, bias=True)
        Post layer function : GELU(approximate=&#39;none&#39;)
        Allow growing : False
        Store input : False
        self._internal_store_input=False
        Store pre-activity : False
        self._internal_store_pre_activity=False
        Tensor S (internal) : S(LinearGrowingModule(first_layer)) tensor of shape (2, 2) with 0 samples
        Tensor S : S(LinearGrowingModule(first_layer)) tensor of shape (2, 2) with 0 samples
        Tensor M : M(LinearGrowingModule(first_layer)) tensor of shape (2, 3) with 0 samples
        Optimal delta layer : None
        Extended input layer : None
        Extended output layer : None
LinearGrowingModule(second_layer) module with 4 parameters.
        Layer : Linear(in_features=3, out_features=1, bias=True)
        Post layer function : Identity()
        Allow growing : False
        Store input : False
        self._internal_store_input=False
        Store pre-activity : False
        self._internal_store_pre_activity=False
        Tensor S (internal) : S(LinearGrowingModule(second_layer)) tensor of shape (4, 4) with 0 samples
        Tensor S : S(LinearGrowingModule(second_layer)) tensor of shape (4, 4) with 0 samples
        Tensor M : M(LinearGrowingModule(second_layer)) tensor of shape (4, 1) with 0 samples
        Optimal delta layer : None
        Extended input layer : None
        Extended output layer : None
</pre></div>
</div>
</section>
<section id="use-your-grown-model">
<h3>6. Use your grown model<a class="headerlink" href="#use-your-grown-model" title="Link to this heading">#</a></h3>
<p>You then get a fully working model that can be used like a normal
PyTorch model. You can train it, evaluate it, etc.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">l2_err</span></a> <span class="o">=</span> <span class="n">evaluate_model</span><span class="p">(</span><span class="n">growing_net</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">loss_function</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;New error: </span><span class="si">{</span><a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">l2_err</span></a><span class="si">:</span><span class="s2">.2e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.figure.Figure.html#matplotlib.figure.Figure" title="matplotlib.figure.Figure" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fig</span></a><span class="p">,</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="matplotlib.axes.Axes" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span></a> <span class="o">=</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt_model</span><span class="p">(</span><span class="n">growing_net</span><span class="p">,</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="matplotlib.axes.Axes" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span></a><span class="p">)</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_plot_tutorial_005.png" srcset="../_images/sphx_glr_plot_tutorial_005.png" alt="plot tutorial" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>New error: 3.99e-02
</pre></div>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">growing_net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="fm">__str__</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">growing_net</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="fm">__str__</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>LinearGrowingModule(first_layer) module with 6 parameters.
        Layer : Linear(in_features=1, out_features=3, bias=True)
        Post layer function : GELU(approximate=&#39;none&#39;)
        Allow growing : False
        Store input : False
        self._internal_store_input=False
        Store pre-activity : False
        self._internal_store_pre_activity=False
        Tensor S (internal) : S(LinearGrowingModule(first_layer)) tensor of shape (2, 2) with 0 samples
        Tensor S : S(LinearGrowingModule(first_layer)) tensor of shape (2, 2) with 0 samples
        Tensor M : M(LinearGrowingModule(first_layer)) tensor of shape (2, 3) with 0 samples
        Optimal delta layer : None
        Extended input layer : None
        Extended output layer : None
LinearGrowingModule(second_layer) module with 4 parameters.
        Layer : Linear(in_features=3, out_features=1, bias=True)
        Post layer function : Identity()
        Allow growing : False
        Store input : False
        self._internal_store_input=False
        Store pre-activity : False
        self._internal_store_pre_activity=False
        Tensor S (internal) : S(LinearGrowingModule(second_layer)) tensor of shape (4, 4) with 0 samples
        Tensor S : S(LinearGrowingModule(second_layer)) tensor of shape (4, 4) with 0 samples
        Tensor M : M(LinearGrowingModule(second_layer)) tensor of shape (4, 1) with 0 samples
        Optimal delta layer : None
        Extended input layer : None
        Extended output layer : None
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 0.386 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-plot-tutorial-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/706f65884faeaa9dfb13933db5a13d6a/plot_tutorial.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_tutorial.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/43d70eb4b9ed18f8f34451c0af07d6f1/plot_tutorial.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_tutorial.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../_downloads/43fabba74407773f301fe9ed164b1548/plot_tutorial.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">plot_tutorial.zip</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="plot_mlp_run.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">MLP Example with Growing Layers</p>
      </div>
    </a>
    <a class="right-next"
       href="../api.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">API Reference</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#imports">Imports</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#define-the-model">1. Define the model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#use-it-like-a-normal-model">2. Use it like a normal model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prepare-the-growth">3. Prepare the growth</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#choose-a-scaling-factor">4. Choose a scaling factor</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#apply-the-changes">5. Apply the changes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#use-your-grown-model">6. Use your grown model</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
       Copyright 2024-2025 GroMo contributors.
      <br/>
    
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>